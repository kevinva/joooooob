{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40350705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1c4026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hoho_RL/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/hoho_RL/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a9e0e3",
   "metadata": {},
   "source": [
    "### two-stage\n",
    "\n",
    "目标检测分两步： 获取候选区域，然后进行分类\n",
    "\n",
    "算法：R-CNN系列\n",
    "\n",
    "### one-stage\n",
    "\n",
    "一步到位。\n",
    "\n",
    "算法：SSD、 YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcb6984",
   "metadata": {},
   "source": [
    "### 常见方法\n",
    "\n",
    "* 滑动窗口法\n",
    "\n",
    "暴力法\n",
    "\n",
    "* R-CNN\n",
    "\n",
    "通过候选区域获取感兴趣区域(ROI)：首先将每个像素作为一组。然后，计算每一组的纹理，并将两个最接近的组结合起来。继续合并区域，直到所有区域都结合在一起\n",
    "![./hoho_image1.png](./hoho_image1.png)\n",
    "\n",
    "之后使用SVM对区域进行分类，使用线性回归损失来校正边界框。\n",
    "\n",
    "流程图如下：\n",
    "![./hoho_image2.png](./hoho_image2.png)\n",
    "\n",
    "\n",
    "* Fast R-CNN\n",
    "\n",
    "使用CNN网络先提取整个图像的特征，而不是对每个图像块提取多次。然后，我们可以将创建候选区域的方法直接应用到提取到的特征图(feature map)上。\n",
    "\n",
    "\n",
    "![./hoho_image3.png](./hoho_image3.png)\n",
    "\n",
    "其中，使用ROI pooling将不同大小的候选区域输出固定大小的特征图：\n",
    "\n",
    "![./hoho_image6.png](./hoho_image6.png)\n",
    "\n",
    "总体流程如下：\n",
    "\n",
    "![./hoho_image4.png](./hoho_image4.png)\n",
    "\n",
    "\n",
    "* Faster R-CNN\n",
    "\n",
    "Fast R-CNN 依赖于外部候选区域方法，如选择性搜索（跟R-CNN一样）。Faster R-CNN 采用与 Fast R-CNN 相同的设计，只是它用区域生成网络（Region Proposal Network，RPN）代替了候选区域方法，让网络自己学习自己的候选区域应该是什么。\n",
    "\n",
    "![./hoho_image5.png](./hoho_image5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72843a97",
   "metadata": {},
   "source": [
    "### YOLO\n",
    "\n",
    "就是一连串的卷积神经网络\n",
    "\n",
    "![./hoho_image7.png](./hoho_image7.png)\n",
    "\n",
    "神经网络会把448的图最后给卷积成7x7。正好就是7x7的格子。每个格子算出来就是一个点。当然有30个通道。所以每个格子其实映射出了30维的一个向量。\n",
    "\n",
    "![./hoho_image8.png](./hoho_image8.png)\n",
    "\n",
    "这30维向量，每个维度作用如下：\n",
    "\n",
    "![./hoho_image9.png](./hoho_image9.png)\n",
    "\n",
    "\n",
    "最后从这两个框里选出一个来。最多有7x7x2个框。丢掉置信度小的，合并同一个类别，就得到了识别结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b97a90",
   "metadata": {},
   "source": [
    "### SSD\n",
    "\n",
    "其实也是一连串卷积神经网络的堆叠，于YOLO差不多\n",
    "\n",
    "![./hoho_image10.png](./hoho_image10.png)\n",
    "\n",
    "SSD的框框是预设好的，各种大小的feature map上都有(多个尺度的feature map)。没有YOLO往出来算框框哪一步。由于各个尺寸上都预设了框框。所以最终框出来结果不错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e42b27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
